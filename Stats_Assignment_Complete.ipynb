{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dff8d59",
   "metadata": {},
   "source": [
    "# Statistics & Probability Assignment\n",
    "\n",
    "Complete solutions (code + brief explanations) for Q1–Q24. Run each code cell in Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2989536c",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Generate a list of 100 integers between 90 and 130 stored in `int_list`. Then implement:\n",
    "\n",
    "(i) mean function\n",
    "\n",
    "(ii) mode of a list\n",
    "\n",
    "(iii) weighted mean\n",
    "\n",
    "(iv) geometric mean\n",
    "\n",
    "(v) harmonic mean\n",
    "\n",
    "(vi) midrange\n",
    "\n",
    "(vii) trimmed mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "from collections import Counter\n",
    "import math\n",
    "import statistics\n",
    "from typing import List, Iterable, Tuple\n",
    "\n",
    "random.seed(0)\n",
    "int_list = [random.randint(90,130) for _ in range(100)]\n",
    "print(\"int_list sample (first 20):\", int_list[:20])\n",
    "\n",
    "# (i) Mean\n",
    "def mean(lst: Iterable[float]) -> float:\n",
    "    lst = list(lst)\n",
    "    return sum(lst)/len(lst) if lst else float('nan')\n",
    "\n",
    "print(\"Mean:\", mean(int_list))\n",
    "\n",
    "# (ii) Mode (may be multimodal) - return list of modes\n",
    "def mode_list(lst: Iterable[int]) -> List[int]:\n",
    "    if not lst:\n",
    "        return []\n",
    "    c = Counter(lst)\n",
    "    max_count = max(c.values())\n",
    "    return [val for val,count in c.items() if count==max_count]\n",
    "\n",
    "print(\"Mode(s):\", mode_list(int_list))\n",
    "\n",
    "# (iii) Weighted mean\n",
    "def weighted_mean(values: Iterable[float], weights: Iterable[float]) -> float:\n",
    "    v = list(values); w = list(weights)\n",
    "    if len(v) != len(w) or not v:\n",
    "        raise ValueError(\"values and weights must be same non-zero length\")\n",
    "    return sum(vi*wi for vi,wi in zip(v,w))/sum(w)\n",
    "\n",
    "# Example weights (positive)\n",
    "weights = [random.uniform(0.5,2.0) for _ in range(len(int_list))]\n",
    "print(\"Weighted mean (example):\", weighted_mean(int_list, weights))\n",
    "\n",
    "# (iv) Geometric mean (only positive values)\n",
    "def geometric_mean(lst: Iterable[float]) -> float:\n",
    "    lst = list(lst)\n",
    "    if any(x<=0 for x in lst):\n",
    "        raise ValueError(\"geometric mean defined for positive numbers only\")\n",
    "    log_sum = sum(math.log(x) for x in lst)\n",
    "    return math.exp(log_sum/len(lst))\n",
    "\n",
    "print(\"Geometric mean:\", geometric_mean(int_list))\n",
    "\n",
    "# (v) Harmonic mean\n",
    "def harmonic_mean(lst: Iterable[float]) -> float:\n",
    "    lst = list(lst)\n",
    "    if any(x==0 for x in lst):\n",
    "        raise ValueError(\"harmonic mean not defined when any value is 0\")\n",
    "    return len(lst)/sum(1.0/x for x in lst)\n",
    "\n",
    "print(\"Harmonic mean:\", harmonic_mean(int_list))\n",
    "\n",
    "# (vi) Midrange\n",
    "def midrange(lst: Iterable[float]) -> float:\n",
    "    lst = list(lst)\n",
    "    return (min(lst)+max(lst))/2.0\n",
    "\n",
    "print(\"Midrange:\", midrange(int_list))\n",
    "\n",
    "# (vii) Trimmed mean: remove given percent from both ends\n",
    "def trimmed_mean(lst: Iterable[float], proportion_to_cut: float) -> float:\n",
    "    if not 0<=proportion_to_cut<0.5:\n",
    "        raise ValueError(\"proportion_to_cut must be in [0,0.5)\")\n",
    "    lst = sorted(lst)\n",
    "    n = len(lst)\n",
    "    k = int(n * proportion_to_cut)\n",
    "    trimmed = lst[k:n-k] if n-2*k>0 else []\n",
    "    return mean(trimmed) if trimmed else float('nan')\n",
    "\n",
    "print(\"Trimmed mean (10%):\", trimmed_mean(int_list, 0.10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7fbf45",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Generate `int_list2` with 500 integers between 200 and 300. Then:\n",
    "\n",
    "(i) Visual comparisons: frequency histogram + Gaussian fit, KDE, overlay\n",
    "\n",
    "(ii) range\n",
    "\n",
    "(iii) variance & std\n",
    "\n",
    "(iv) IQR\n",
    "\n",
    "(v) coefficient of variation\n",
    "\n",
    "(vi) MAD\n",
    "\n",
    "(vii) quartile deviation\n",
    "\n",
    "(viii) range-based coefficient of dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3355ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "np.random.seed(0)\n",
    "int_list2 = list(np.random.randint(200,301,size=500))\n",
    "print(\"int_list2 sample (first 20):\", int_list2[:20])\n",
    "\n",
    "# (i) Visual comparisons\n",
    "data = np.array(int_list2)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,3,1)\n",
    "# Frequency histogram + Gaussian fit\n",
    "sns.histplot(data, bins=20, kde=False)\n",
    "mu, std = data.mean(), data.std(ddof=0)\n",
    "xmin, xmax = data.min(), data.max()\n",
    "x = np.linspace(xmin, xmax, 200)\n",
    "plt.plot(x, 500*(x[1]-x[0])*stats.norm.pdf(x, mu, std), label=f'Normal fit (mu={mu:.1f}, std={std:.1f})')\n",
    "plt.title(\"Frequency + Gaussian fit\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "# Frequency smoothened KDE plot\n",
    "sns.kdeplot(data, bw_method='scott')\n",
    "plt.title(\"KDE (smoothed)\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "# Gaussian distribution curve + smooth KDE overlay\n",
    "sns.histplot(data, bins=20, kde=False, stat='density', alpha=0.4)\n",
    "sns.kdeplot(data, bw_method='scott', label='KDE')\n",
    "plt.plot(x, stats.norm.pdf(x, mu, std), label='Normal PDF')\n",
    "plt.title(\"Gaussian PDF & KDE\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# (ii) Range\n",
    "def data_range(lst: Iterable[float]) -> float:\n",
    "    lst = list(lst)\n",
    "    return max(lst)-min(lst)\n",
    "\n",
    "print(\"Range:\", data_range(int_list2))\n",
    "\n",
    "# (iii) Variance & std (sample & population)\n",
    "def variance_and_std(lst: Iterable[float], sample: bool=True) -> Tuple[float,float]:\n",
    "    arr = np.array(lst)\n",
    "    if sample:\n",
    "        var = arr.var(ddof=1)\n",
    "        sd = arr.std(ddof=1)\n",
    "    else:\n",
    "        var = arr.var(ddof=0)\n",
    "        sd = arr.std(ddof=0)\n",
    "    return var, sd\n",
    "\n",
    "print(\"Sample variance & std:\", variance_and_std(int_list2, sample=True))\n",
    "\n",
    "# (iv) IQR\n",
    "def iqr(lst: Iterable[float]) -> float:\n",
    "    q75, q25 = np.percentile(lst, [75,25])\n",
    "    return q75 - q25\n",
    "\n",
    "print(\"IQR:\", iqr(int_list2))\n",
    "\n",
    "# (v) Coefficient of variation (CV = sd/mean)\n",
    "def coefficient_of_variation(lst: Iterable[float], sample: bool=True) -> float:\n",
    "    arr = np.array(lst)\n",
    "    sd = arr.std(ddof=1) if sample else arr.std(ddof=0)\n",
    "    return sd/arr.mean()\n",
    "\n",
    "print(\"Coefficient of Variation:\", coefficient_of_variation(int_list2))\n",
    "\n",
    "# (vi) Mean absolute deviation (MAD) about the mean\n",
    "def mad(lst: Iterable[float]) -> float:\n",
    "    arr = np.array(lst)\n",
    "    return np.mean(np.abs(arr - arr.mean()))\n",
    "\n",
    "print(\"MAD:\", mad(int_list2))\n",
    "\n",
    "# (vii) Quartile deviation (semi-interquartile range)\n",
    "def quartile_deviation(lst: Iterable[float]) -> float:\n",
    "    return iqr(lst)/2.0\n",
    "\n",
    "print(\"Quartile Deviation:\", quartile_deviation(int_list2))\n",
    "\n",
    "# (viii) Range-based coefficient of dispersion = (max-min)/(max+min)\n",
    "def range_based_coefficient_of_dispersion(lst: Iterable[float]) -> float:\n",
    "    arr = np.array(lst)\n",
    "    return (arr.max() - arr.min())/(arr.max() + arr.min())\n",
    "\n",
    "print(\"Range-based Coefficient of Dispersion:\", range_based_coefficient_of_dispersion(int_list2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed96bf2",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Create a Python class for a discrete random variable with methods to compute expected value and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6b5a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DiscreteRV:\n",
    "    def __init__(self, outcomes: Iterable[float], probs: Iterable[float]):\n",
    "        self.outcomes = list(outcomes)\n",
    "        self.probs = list(probs)\n",
    "        if not math.isclose(sum(self.probs), 1.0, rel_tol=1e-6):\n",
    "            raise ValueError(\"Probabilities must sum to 1\")\n",
    "    def expected_value(self):\n",
    "        return sum(x*p for x,p in zip(self.outcomes,self.probs))\n",
    "    def variance(self):\n",
    "        mu = self.expected_value()\n",
    "        return sum(((x-mu)**2)*p for x,p in zip(self.outcomes,self.probs))\n",
    "\n",
    "# Example\n",
    "rv = DiscreteRV([0,1], [0.6,0.4])\n",
    "print(\"Expected value:\", rv.expected_value())\n",
    "print(\"Variance:\", rv.variance())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2971a0",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Simulate rolling a fair six-sided die many times and calculate expected value and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c927ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def simulate_die_rolls(n=10000):\n",
    "    rolls = [random.randint(1,6) for _ in range(n)]\n",
    "    return np.mean(rolls), np.var(rolls, ddof=0)\n",
    "\n",
    "mean_sim, var_sim = simulate_die_rolls(100000)\n",
    "print(\"Simulated mean:\", mean_sim)\n",
    "print(\"Simulated variance:\", var_sim)\n",
    "\n",
    "# Theoretical values: mean = 3.5, variance = 35/12 ≈ 2.9167\n",
    "print(\"Theoretical mean:\", 3.5, \"Theoretical variance:\", 35/12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e107a86",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Generate random samples from distributions (binomial, Poisson) and compute mean & variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81988b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def sample_binomial(n_trials=10, p=0.3, size=1000):\n",
    "    s = np.random.binomial(n_trials, p, size=size)\n",
    "    return s, s.mean(), s.var(ddof=0)\n",
    "\n",
    "def sample_poisson(lam=3, size=1000):\n",
    "    s = np.random.poisson(lam, size=size)\n",
    "    return s, s.mean(), s.var(ddof=0)\n",
    "\n",
    "b_s, b_mean, b_var = sample_binomial(10, 0.3, 10000)\n",
    "p_s, p_mean, p_var = sample_poisson(3, 10000)\n",
    "print(\"Binomial mean/var:\", b_mean, b_var)\n",
    "print(\"Poisson mean/var:\", p_mean, p_var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f532a324",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "Generate random numbers from Gaussian distribution and compute mean, variance, std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7509c299",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s = np.random.normal(loc=50, scale=5, size=10000)\n",
    "print(\"Sample mean:\", s.mean())\n",
    "print(\"Sample variance:\", s.var(ddof=0))\n",
    "print(\"Sample std:\", s.std(ddof=0))\n",
    "\n",
    "# Quick histogram\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.histplot(s, bins=30, stat='density')\n",
    "plt.title(\"Normal samples histogram\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895b1804",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "Load seaborn 'tips' dataset and analyze 'total_bill' and 'tip' columns:\n",
    "(i) skewness\n",
    "(ii) decide pos/neg/symmetric\n",
    "(iii) covariance\n",
    "(iv) Pearson correlation\n",
    "(v) scatter plot visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b640e484",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tips = sns.load_dataset('tips')\n",
    "cols = ['total_bill','tip']\n",
    "\n",
    "# (i) skewness\n",
    "def skewness(arr):\n",
    "    return float(stats.skew(arr))\n",
    "\n",
    "print(\"Skewness total_bill:\", skewness(tips['total_bill']))\n",
    "print(\"Skewness tip:\", skewness(tips['tip']))\n",
    "\n",
    "# (ii) decide type\n",
    "def skew_type(arr):\n",
    "    s = skewness(arr)\n",
    "    if s > 0.5:\n",
    "        return \"Positive skew\"\n",
    "    elif s < -0.5:\n",
    "        return \"Negative skew\"\n",
    "    else:\n",
    "        return \"Approximately symmetric\"\n",
    "\n",
    "print(\"total_bill:\", skew_type(tips['total_bill']))\n",
    "print(\"tip:\", skew_type(tips['tip']))\n",
    "\n",
    "# (iii) covariance\n",
    "def covariance(x,y):\n",
    "    x,y = np.array(x), np.array(y)\n",
    "    return ((x - x.mean())*(y - y.mean())).sum()/(len(x)-1)\n",
    "\n",
    "print(\"Covariance:\", covariance(tips['total_bill'], tips['tip']))\n",
    "\n",
    "# (iv) Pearson correlation\n",
    "r, pval = stats.pearsonr(tips['total_bill'], tips['tip'])\n",
    "print(\"Pearson r:\", r, \"p-value:\", pval)\n",
    "\n",
    "# (v) Scatter plot\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.scatterplot(x='total_bill', y='tip', data=tips)\n",
    "plt.title(\"Scatter: total_bill vs tip\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb85f46",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "Function for PDF of normal distribution (continuous RV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fe5af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normal_pdf(x, mu=0, sigma=1):\n",
    "    coef = 1.0/(sigma * math.sqrt(2*math.pi))\n",
    "    exp_term = math.exp(-0.5 * ((x-mu)/sigma)**2)\n",
    "    return coef * exp_term\n",
    "\n",
    "print(\"Normal PDF at 0 (mu=0,sigma=1):\", normal_pdf(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9df0e5f",
   "metadata": {},
   "source": [
    "## Question 9\n",
    "CDF of exponential distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17005327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def exponential_cdf(x, lambd=1.0):\n",
    "    if x < 0:\n",
    "        return 0.0\n",
    "    return 1 - math.exp(-lambd * x)\n",
    "\n",
    "print(\"Exponential CDF at x=1, lambda=1:\", exponential_cdf(1,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b77f2",
   "metadata": {},
   "source": [
    "## Question 10\n",
    "PMF of Poisson distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def poisson_pmf(k, lam):\n",
    "    return math.exp(-lam) * lam**k / math.factorial(k)\n",
    "\n",
    "print(\"Poisson PMF k=2, lambda=3:\", poisson_pmf(2,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11217e6c",
   "metadata": {},
   "source": [
    "## Question 11\n",
    "Z-test for proportions: compare conversion rates of old and new layouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f08cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "old_layout = np.array([1]*50 + [0]*950)\n",
    "new_layout = np.array([1]*70 + [0]*930)\n",
    "\n",
    "def z_test_proportions(a, b):\n",
    "    pa = a.mean(); pb = b.mean()\n",
    "    n1 = len(a); n2 = len(b)\n",
    "    p_pool = (a.sum() + b.sum())/(n1 + n2)\n",
    "    se = math.sqrt(p_pool*(1-p_pool)*(1/n1 + 1/n2))\n",
    "    z = (pb - pa)/se\n",
    "    # two-sided p-value\n",
    "    p = 2*(1 - stats.norm.cdf(abs(z)))\n",
    "    return z, p, pa, pb\n",
    "\n",
    "z, p, pa, pb = z_test_proportions(old_layout, new_layout)\n",
    "print(\"old p:\", pa, \"new p:\", pb, \"z:\", z, \"p-value:\", p)\n",
    "if p < 0.05 and z>0:\n",
    "    print(\"New layout has significantly higher conversion rate (reject H0).\")\n",
    "else:\n",
    "    print(\"No significant improvement detected at alpha=0.05.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d14e089",
   "metadata": {},
   "source": [
    "## Question 12\n",
    "Z-test for before/after program scores (paired)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c3dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "before_program = np.array([75,80,85,70,90,78,92,88,82,87])\n",
    "after_program = np.array([80,85,90,80,92,80,95,90,85,88])\n",
    "\n",
    "# For paired samples, compute differences and use z-test approx (n small, better use t-test but we use z as requested)\n",
    "diff = after_program - before_program\n",
    "dz = diff.mean() / (diff.std(ddof=0)/math.sqrt(len(diff)))\n",
    "p_val = 2*(1 - stats.norm.cdf(abs(dz)))\n",
    "print(\"z-stat:\", dz, \"p-value:\", p_val)\n",
    "if p_val < 0.05:\n",
    "    print(\"Significant improvement after program (reject H0).\")\n",
    "else:\n",
    "    print(\"No significant improvement detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff02200",
   "metadata": {},
   "source": [
    "## Question 13\n",
    "Z-test for blood pressure before/after drug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae89513",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "before_drug = np.array([145,150,140,135,155,160,152,148,130,138])\n",
    "after_drug = np.array([130,140,132,128,145,148,138,136,125,130])\n",
    "\n",
    "diff = before_drug - after_drug  # reduction\n",
    "z_stat = diff.mean() / (diff.std(ddof=0)/math.sqrt(len(diff)))\n",
    "p_val = 2*(1 - stats.norm.cdf(abs(z_stat)))\n",
    "print(\"z-stat:\", z_stat, \"p-value:\", p_val)\n",
    "if p_val < 0.05 and z_stat>0:\n",
    "    print(\"Drug appears effective (significant reduction).\")\n",
    "else:\n",
    "    print(\"No significant evidence of effect at alpha=0.05.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936fb38a",
   "metadata": {},
   "source": [
    "## Question 14\n",
    "Z-test: response times claim (mean < 5). One-sided test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3567b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response_times = np.array([4.3,3.8,5.1,4.9,4.7,4.2,5.2,4.5,4.6,4.4])\n",
    "# H0: mu = 5, H1: mu < 5\n",
    "mu0 = 5.0\n",
    "n = len(response_times)\n",
    "z = (response_times.mean() - mu0) / (response_times.std(ddof=0)/math.sqrt(n))\n",
    "p_one_sided = stats.norm.cdf(z)  # lower tail\n",
    "print(\"z:\", z, \"one-sided p:\", p_one_sided)\n",
    "if p_one_sided < 0.05:\n",
    "    print(\"Claim (mean < 5) supported at alpha=0.05.\")\n",
    "else:\n",
    "    print(\"Insufficient evidence to support claim.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f8b645",
   "metadata": {},
   "source": [
    "## Question 15\n",
    "A/B test: two samples of clicks. Compute t-statistic, df, p-value (Welch's t-test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d83f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layout_a_clicks = np.array([28,32,33,29,31,34,30,35,36,37])\n",
    "layout_b_clicks = np.array([40,41,38,42,39,44,43,41,45,47])\n",
    "\n",
    "# Welch's t-test\n",
    "t_stat, p_val = stats.ttest_ind(layout_b_clicks, layout_a_clicks, equal_var=False)\n",
    "# approximate df for Welch is returned via formula; scipy doesn't return df directly\n",
    "def welch_df(a,b):\n",
    "    sa2 = a.var(ddof=1); sb2 = b.var(ddof=1)\n",
    "    n1, n2 = len(a), len(b)\n",
    "    num = (sa2/n1 + sb2/n2)**2\n",
    "    den = (sa2**2)/((n1**2)*(n1-1)) + (sb2**2)/((n2**2)*(n2-1))\n",
    "    return num/den\n",
    "\n",
    "df = welch_df(layout_b_clicks, layout_a_clicks)\n",
    "print(\"t-stat:\", t_stat, \"p-value:\", p_val, \"df (approx):\", df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd092d0a",
   "metadata": {},
   "source": [
    "## Question 16\n",
    "Compare existing vs new drug cholesterol levels (two-sample t-test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac89e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "existing_drug_levels = np.array([180,182,175,185,178,176,172,184,179,183])\n",
    "new_drug_levels = np.array([170,172,165,168,175,173,170,178,172,176])\n",
    "\n",
    "t_stat, p_val = stats.ttest_ind(existing_drug_levels, new_drug_levels, equal_var=False)\n",
    "df = welch_df(existing_drug_levels, new_drug_levels)\n",
    "print(\"t-stat:\", t_stat, \"p-value:\", p_val, \"df approx:\", df)\n",
    "if p_val < 0.05:\n",
    "    print(\"Significant difference between drugs.\")\n",
    "else:\n",
    "    print(\"No significant difference detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b79998",
   "metadata": {},
   "source": [
    "## Question 17\n",
    "Pre/post intervention paired t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d0fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pre_intervention_scores = np.array([80,85,90,75,88,82,92,78,85,87])\n",
    "post_intervention_scores = np.array([90,92,88,92,95,91,96,93,89,93])\n",
    "\n",
    "t_stat, p_val = stats.ttest_rel(post_intervention_scores, pre_intervention_scores)\n",
    "print(\"paired t-stat:\", t_stat, \"p-value:\", p_val)\n",
    "if p_val < 0.05:\n",
    "    print(\"Intervention had a significant impact.\")\n",
    "else:\n",
    "    print(\"No significant impact found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7ae2fa",
   "metadata": {},
   "source": [
    "## Question 18\n",
    "Two-sample t-test for male vs female salaries (synthetic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4915fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "male_salaries = np.random.normal(loc=50000, scale=10000, size=20)\n",
    "female_salaries = np.random.normal(loc=55000, scale=9000, size=20)\n",
    "\n",
    "t_stat, p_val = stats.ttest_ind(male_salaries, female_salaries, equal_var=False)\n",
    "df = welch_df(male_salaries, female_salaries)\n",
    "print(\"t-stat:\", t_stat, \"p-value:\", p_val, \"df approx:\", df)\n",
    "if p_val < 0.05:\n",
    "    print(\"Significant salary difference detected.\")\n",
    "else:\n",
    "    print(\"No significant difference detected at alpha=0.05.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffc18b9",
   "metadata": {},
   "source": [
    "## Question 19\n",
    "Compare version1 vs version2 quality scores (two-sample t-test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8baa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "version1_scores = np.array([85,88,82,89,87,84,90,88,85,86,91,83,87,84,89,86,84,88,85,86,89,90,87,88,85])\n",
    "version2_scores = np.array([80,78,83,81,79,82,76,80,78,81,77,82,80,79,82,79,80,81,79,82,79,78,80,81,82])\n",
    "\n",
    "t_stat, p_val = stats.ttest_ind(version1_scores, version2_scores, equal_var=False)\n",
    "df = welch_df(version1_scores, version2_scores)\n",
    "print(\"t-stat:\", t_stat, \"p-value:\", p_val, \"df approx:\", df)\n",
    "if p_val < 0.05:\n",
    "    print(\"Significant difference in quality.\")\n",
    "else:\n",
    "    print(\"No significant difference found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ccb61e",
   "metadata": {},
   "source": [
    "## Question 20\n",
    "Compare branch A vs B customer satisfaction (two-sample t-test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678dfe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "branch_a_scores = np.array([4,3,4,5,4,5,3,4,4,5,4,4,3,4,5,4,3,5,4,4,5,4,3,5,4,4])\n",
    "branch_b_scores = np.array([3,4,2,3,4,3,4,2,3,3,4,3,3,2,4,3,4,2,3,4,3,3,4,2,3,4,3])\n",
    "\n",
    "t_stat, p_val = stats.ttest_ind(branch_a_scores, branch_b_scores, equal_var=False)\n",
    "df = welch_df(branch_a_scores, branch_b_scores)\n",
    "print(\"t-stat:\", t_stat, \"p-value:\", p_val, \"df approx:\", df)\n",
    "if p_val < 0.05:\n",
    "    print(\"Significant difference in satisfaction.\")\n",
    "else:\n",
    "    print(\"No significant difference found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f736b5",
   "metadata": {},
   "source": [
    "## Question 21\n",
    "Chi-Square test for association between age groups and voter preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b137b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "age_groups = np.random.choice(['18-30','31-50','51+'], size=30)\n",
    "voter_preferences = np.random.choice(['Candidate A','Candidate B'], size=30)\n",
    "\n",
    "# Build contingency table\n",
    "import pandas as pd\n",
    "ct = pd.crosstab(age_groups, voter_preferences)\n",
    "print(\"Contingency table:\\n\", ct)\n",
    "\n",
    "chi2, p, dof, expected = stats.chi2_contingency(ct)\n",
    "print(\"chi2:\", chi2, \"p-value:\", p, \"dof:\", dof)\n",
    "if p < 0.05:\n",
    "    print(\"Significant association between age group and preference.\")\n",
    "else:\n",
    "    print(\"No significant association detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74afae45",
   "metadata": {},
   "source": [
    "## Question 22\n",
    "Chi-Square test on product satisfaction vs region (provided contingency table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a07084",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = np.array([[50,30,40,20], [30,40,30,50], [20,30,40,30]])\n",
    "chi2, p, dof, expected = stats.chi2_contingency(data)\n",
    "print(\"chi2:\", chi2, \"p-value:\", p, \"dof:\", dof)\n",
    "print(\"Expected counts:\\n\", expected)\n",
    "if p < 0.05:\n",
    "    print(\"Significant relationship between satisfaction and region.\")\n",
    "else:\n",
    "    print(\"No significant relationship detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f3fbb2",
   "metadata": {},
   "source": [
    "## Question 23\n",
    "Chi-Square test for job performance before vs after training (provided table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6683d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = np.array([[50,30,20], [30,40,30], [20,30,40]])\n",
    "chi2, p, dof, expected = stats.chi2_contingency(data)\n",
    "print(\"chi2:\", chi2, \"p-value:\", p, \"dof:\", dof)\n",
    "if p < 0.05:\n",
    "    print(\"Significant change in job performance distribution.\")\n",
    "else:\n",
    "    print(\"No significant change detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777c66c6",
   "metadata": {},
   "source": [
    "## Question 24\n",
    "ANOVA to test difference among Standard, Premium, Deluxe satisfaction scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ff2c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "standard_scores = np.array([80,85,90,78,88,82,92,78,85,87])\n",
    "premium_scores = np.array([90,92,88,92,95,91,96,93,89,93])\n",
    "deluxe_scores = np.array([95,98,92,97,96,94,98,97,92,99])\n",
    "\n",
    "f_stat, p_val = stats.f_oneway(standard_scores, premium_scores, deluxe_scores)\n",
    "print(\"ANOVA F-stat:\", f_stat, \"p-value:\", p_val)\n",
    "if p_val < 0.05:\n",
    "    print(\"At least one group mean differs significantly.\")\n",
    "else:\n",
    "    print(\"No evidence of difference among group means.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
