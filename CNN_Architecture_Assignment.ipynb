{"nbformat": 4, "nbformat_minor": 5, "metadata": {}, "cells": [{"id": "376e1521", "cell_type": "markdown", "source": "# \ud83e\udde0 CNN Architecture Assignment\nThis notebook contains **theory + practical** solutions for CNN Architecture.", "metadata": {}}, {"id": "991f8464", "cell_type": "markdown", "source": "**1. What is a Convolutional Neural Network (CNN), and why is it used for image processing?**\n\nCNN is a type of deep neural network specialized for processing grid-like data such as images. It learns spatial hierarchies using convolution operations, making it excellent for image recognition tasks.", "metadata": {}}, {"id": "2c81e144", "cell_type": "markdown", "source": "**2. What are the key components of a CNN architecture?**\n\nKey components: Convolutional layers, activation functions (ReLU), pooling layers, fully connected layers, and output layer.", "metadata": {}}, {"id": "898c63e0", "cell_type": "markdown", "source": "**3. What is the role of the convolutional layer in CNNs?**\n\nConvolutional layer extracts feature maps from input images using filters that slide over the input.", "metadata": {}}, {"id": "c4a189c8", "cell_type": "markdown", "source": "**4. What is a filter (kernel) in CNNs?**\n\nA filter (kernel) is a small matrix that performs element-wise multiplication with parts of the input to detect features like edges.", "metadata": {}}, {"id": "5398f2c0", "cell_type": "markdown", "source": "**5. What is pooling in CNNs, and why is it important?**\n\nPooling reduces spatial dimensions, helping in down-sampling and reducing computation while keeping important features.", "metadata": {}}, {"id": "05478349", "cell_type": "markdown", "source": "**6. What are the common types of pooling used in CNNs?**\n\nCommon types: Max pooling (takes max value) and Average pooling (takes mean value).", "metadata": {}}, {"id": "a30e3e75", "cell_type": "markdown", "source": "**7. How does the backpropagation algorithm work in CNNs?**\n\nBackpropagation updates filter weights using gradient descent based on the loss, just like in fully connected networks.", "metadata": {}}, {"id": "0bb068af", "cell_type": "markdown", "source": "**8. What is the role of activation functions in CNNs?**\n\nActivation functions introduce non-linearity, allowing CNNs to learn complex patterns.", "metadata": {}}, {"id": "91c34519", "cell_type": "markdown", "source": "**9. What is the concept of receptive fields in CNNs?**\n\nReceptive field is the region of the input image that a particular feature in a layer responds to.", "metadata": {}}, {"id": "72fe7840", "cell_type": "markdown", "source": "**10. Explain the concept of tensor space in CNNs.**\n\nTensor space refers to multi-dimensional representation of data flowing through CNN layers.", "metadata": {}}, {"id": "b890970e", "cell_type": "markdown", "source": "**11. What is LeNet-5, and how does it contribute to the development of CNNs?**\n\nLeNet-5 is one of the earliest CNNs used for handwritten digit recognition (MNIST), proving CNNs' effectiveness.", "metadata": {}}, {"id": "618ed075", "cell_type": "markdown", "source": "**12. What is AlexNet, and why was it a breakthrough in deep learning?**\n\nAlexNet introduced deep CNNs for ImageNet and popularized ReLU, dropout, and GPU training, improving accuracy massively.", "metadata": {}}, {"id": "0f9832ae", "cell_type": "markdown", "source": "**13. What is VGGNet, and how does it differ from AlexNet?**\n\nVGGNet uses very small (3x3) filters but goes very deep (16-19 layers), making it simpler but computationally heavier.", "metadata": {}}, {"id": "3896daed", "cell_type": "markdown", "source": "**14. What is GoogLeNet, and what is its main innovation?**\n\nGoogLeNet introduced Inception modules, allowing multi-scale convolutions in parallel, making network more efficient.", "metadata": {}}, {"id": "6bb1043b", "cell_type": "markdown", "source": "**15. What is ResNet, and what problem does it solve?**\n\nResNet introduced skip connections (residual links) to solve vanishing gradient problem and train very deep networks.", "metadata": {}}, {"id": "4ac54ebd", "cell_type": "markdown", "source": "**16. What is DenseNet, and how does it differ from ResNet?**\n\nDenseNet connects each layer to every other layer, improving gradient flow and parameter efficiency compared to ResNet.", "metadata": {}}, {"id": "0194dcc0", "cell_type": "markdown", "source": "**17. What are the main steps involved in training a CNN from scratch?**\n\nSteps: Data preprocessing, model design, forward pass, loss calculation, backpropagation, parameter update, evaluation.", "metadata": {}}, {"id": "acf60089", "cell_type": "markdown", "source": "## \ud83e\uddd1\u200d\ud83d\udcbb Practical Implementations", "metadata": {}}, {"id": "02a24769", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "import numpy as np\n\n# 1. Basic convolution\nimage = np.random.randint(0, 10, (5,5))\nkernel = np.array([[1,0,-1],[1,0,-1],[1,0,-1]])\noutput = np.zeros((3,3))\n\nfor i in range(3):\n    for j in range(3):\n        output[i,j] = np.sum(image[i:i+3, j:j+3] * kernel)\n\nprint(\"Input Image:\\n\", image)\nprint(\"Filtered Output:\\n\", output)", "outputs": []}, {"id": "7a78ddae", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "# 2. Max Pooling\nfeature_map = np.random.randint(0, 10, (4,4))\npooled = np.zeros((2,2))\nfor i in range(0,4,2):\n    for j in range(0,4,2):\n        pooled[i//2, j//2] = np.max(feature_map[i:i+2, j:j+2])\nprint(\"Feature Map:\\n\", feature_map)\nprint(\"Max Pooled:\\n\", pooled)", "outputs": []}, {"id": "93bbd869", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "# 3. ReLU Activation\nfeature_map = np.array([[-1,2,-3],[4,-5,6]])\nrelu_output = np.maximum(0, feature_map)\nprint(\"ReLU Output:\\n\", relu_output)", "outputs": []}, {"id": "7767100a", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "# 4-13: CNN in Keras\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# Simple CNN model\nmodel = models.Sequential([\n    layers.Conv2D(8, (3,3), activation='relu', input_shape=(28,28,1)),\n    layers.MaxPooling2D((2,2)),\n    layers.BatchNormalization(),\n    layers.Dropout(0.2),\n    layers.Flatten(),\n    layers.Dense(16, activation='relu'),\n    layers.Dense(10, activation='softmax')\n])\n\nmodel.summary()\n\n# Generate synthetic data\nX_train = np.random.rand(100,28,28,1)\ny_train = tf.keras.utils.to_categorical(np.random.randint(0,10,100), 10)\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(X_train, y_train, epochs=3, verbose=1)\n\n# Plot training curves\nimport matplotlib.pyplot as plt\nplt.plot(history.history['loss'], label='Loss')\nplt.plot(history.history['accuracy'], label='Accuracy')\nplt.legend()\nplt.show()\n\n# Print VGG16 and ResNet50 Architectures\nfrom tensorflow.keras.applications import VGG16, ResNet50\nvgg = VGG16()\nresnet = ResNet50()\nprint(\"VGG16 Summary:\")\nvgg.summary()\nprint(\"ResNet50 Summary:\")\nresnet.summary()", "outputs": []}]}